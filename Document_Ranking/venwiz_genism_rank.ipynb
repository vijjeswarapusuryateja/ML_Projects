{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c403106c",
   "metadata": {
    "id": "c403106c"
   },
   "source": [
    "# Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2d08d3b",
   "metadata": {
    "executionInfo": {
     "elapsed": 437,
     "status": "ok",
     "timestamp": 1676118545322,
     "user": {
      "displayName": "Vijjeswarapu Surya Teja",
      "userId": "00235380156444321068"
     },
     "user_tz": -330
    },
    "id": "d2d08d3b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import string\n",
    "import gensim\n",
    "import operator\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5jGaaROUayoE",
   "metadata": {
    "id": "5jGaaROUayoE"
   },
   "source": [
    "\n",
    "# Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78bcfb16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1676118546327,
     "user": {
      "displayName": "Vijjeswarapu Surya Teja",
      "userId": "00235380156444321068"
     },
     "user_tz": -330
    },
    "id": "78bcfb16",
    "outputId": "dd23c10c-d8bc-4180-b786-ae9af5e0a179",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'queries.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7540\\3443086833.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'queries.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mquery_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mqueries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".I\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mqueries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'queries.txt'"
     ]
    }
   ],
   "source": [
    "f=open('queries.txt')\n",
    "query_str = f.read()\n",
    "queries = query_str.split(\".I\")\n",
    "queries[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbe496c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1676118546328,
     "user": {
      "displayName": "Vijjeswarapu Surya Teja",
      "userId": "00235380156444321068"
     },
     "user_tz": -330
    },
    "id": "9dbe496c",
    "outputId": "ea22e972-5d32-40b8-ea70-341fb2cd93a2"
   },
   "outputs": [],
   "source": [
    "queries_data = []\n",
    "for t in queries:\n",
    "    if t.strip() != \"\":\n",
    "        i = t.split(\".W\\n\")[0]\n",
    "        w = t.split(\".W\\n\")[1]\n",
    "        queries_data.append({\"I\": i.strip(), \"W\": w.strip()})\n",
    "\n",
    "df_queries = pd.DataFrame(queries_data)\n",
    "df_queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ca109c7",
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1676118546329,
     "user": {
      "displayName": "Vijjeswarapu Surya Teja",
      "userId": "00235380156444321068"
     },
     "user_tz": -330
    },
    "id": "4ca109c7"
   },
   "outputs": [],
   "source": [
    "f=open('docs.txt')\n",
    "doc_str = f.read()\n",
    "docs = doc_str.split(\".I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b3ead5e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1676118546330,
     "user": {
      "displayName": "Vijjeswarapu Surya Teja",
      "userId": "00235380156444321068"
     },
     "user_tz": -330
    },
    "id": "2b3ead5e",
    "outputId": "ab49c889-d862-4e1f-e035-cc861593253c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>correlation between maternal and fetal plasma ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>changes of the nucleic acid and phospholipid l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>surfactant in fetal lamb tracheal fluid .     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>placental and cord blood lipids.. comparison i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>free fatty acid concentration in maternal plas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   I                                                  W\n",
       "0  1  correlation between maternal and fetal plasma ...\n",
       "1  2  changes of the nucleic acid and phospholipid l...\n",
       "2  3  surfactant in fetal lamb tracheal fluid .     ...\n",
       "3  4  placental and cord blood lipids.. comparison i...\n",
       "4  5  free fatty acid concentration in maternal plas..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_data = []\n",
    "for t in docs:\n",
    "    if t.strip() != \"\":\n",
    "        i = t.split(\".W\\n\")[0]\n",
    "        w = t.split(\".W\\n\")[1]\n",
    "        docs_data.append({\"I\": i.strip(), \"W\": w.strip()})\n",
    "\n",
    "df_docs = pd.DataFrame(docs_data)\n",
    "df_docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d99b499",
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1676118546332,
     "user": {
      "displayName": "Vijjeswarapu Surya Teja",
      "userId": "00235380156444321068"
     },
     "user_tz": -330
    },
    "id": "8d99b499"
   },
   "outputs": [],
   "source": [
    "f=open('relevance.txt')\n",
    "relevance_str = f.read()\n",
    "relevance = relevance_str.strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68cad412",
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1676118546333,
     "user": {
      "displayName": "Vijjeswarapu Surya Teja",
      "userId": "00235380156444321068"
     },
     "user_tz": -330
    },
    "id": "68cad412"
   },
   "outputs": [],
   "source": [
    "# Split each line into columns\n",
    "rows = [list(map(float, line.strip().split())) for line in relevance]\n",
    "\n",
    "# Create a DataFrame from the rows\n",
    "df_relevance = pd.DataFrame(rows, columns=[\"query\", \"doc\", \"col3\", \"col4\"])\n",
    "df_relevance = df_relevance.drop(['col3', 'col4'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59f0ef5a",
   "metadata": {
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1676118546335,
     "user": {
      "displayName": "Vijjeswarapu Surya Teja",
      "userId": "00235380156444321068"
     },
     "user_tz": -330
    },
    "id": "59f0ef5a"
   },
   "outputs": [],
   "source": [
    "df_relevance = df_relevance.astype(int)\n",
    "df_docs['I'] = df_docs['I'].astype(int)\n",
    "df_queries['I'] = df_queries['I'].astype(int)\n",
    "\n",
    "df_rele_doc = pd.merge(df_relevance, df_docs, left_on='doc', right_on='I')\n",
    "\n",
    "df = pd.merge(df_rele_doc, df_queries, left_on='query', right_on='I')\n",
    "\n",
    "df = df.rename(columns={'W_x':'docs', 'W_y':'queries'})\n",
    "\n",
    "final_df = df[['docs', 'queries', 'doc', 'query']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b25cd910",
   "metadata": {
    "executionInfo": {
     "elapsed": 516,
     "status": "ok",
     "timestamp": 1676118546818,
     "user": {
      "displayName": "Vijjeswarapu Surya Teja",
      "userId": "00235380156444321068"
     },
     "user_tz": -330
    },
    "id": "b25cd910"
   },
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "spacy_nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#create list of punctuations and stopwords\n",
    "punctuations = string.punctuation\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "#function for data cleaning and processing\n",
    "#This can be further enhanced by adding / removing reg-exps as desired.\n",
    "\n",
    "def spacy_tokenizer(sentence):\n",
    " \n",
    "    #remove distracting single quotes\n",
    "    sentence = re.sub('\\'','',sentence)\n",
    "\n",
    "    #remove digits adnd words containing digits\n",
    "    sentence = re.sub('\\w*\\d\\w*','',sentence)\n",
    "\n",
    "    #replace extra spaces with single space\n",
    "    sentence = re.sub(' +',' ',sentence)\n",
    "\n",
    "    #remove unwanted lines starting from special charcters\n",
    "    sentence = re.sub(r'\\n: \\'\\'.*','',sentence)\n",
    "    sentence = re.sub(r'\\n!.*','',sentence)\n",
    "    sentence = re.sub(r'^:\\'\\'.*','',sentence)\n",
    "    \n",
    "    #remove non-breaking new line characters\n",
    "    sentence = re.sub(r'\\n',' ',sentence)\n",
    "    \n",
    "    #remove punctunations\n",
    "    sentence = re.sub(r'[^\\w\\s]',' ',sentence)\n",
    "    \n",
    "    #creating token object\n",
    "    tokens = spacy_nlp(sentence)\n",
    "    \n",
    "    #lower, strip and lemmatize\n",
    "    tokens = [word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in tokens]\n",
    "    \n",
    "    #remove stopwords, and exclude words less than 2 characters\n",
    "    tokens = [word for word in tokens if word not in stop_words and word not in punctuations and len(word) > 2]\n",
    "    \n",
    "    #return tokens\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b307a6ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "executionInfo": {
     "elapsed": 24612,
     "status": "ok",
     "timestamp": 1676118571427,
     "user": {
      "displayName": "Vijjeswarapu Surya Teja",
      "userId": "00235380156444321068"
     },
     "user_tz": -330
    },
    "id": "b307a6ea",
    "outputId": "9883f467-083b-4106-e77e-22e6e174fc28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and Tokenizing...\n",
      "Wall time: 53 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docs</th>\n",
       "      <th>queries</th>\n",
       "      <th>doc</th>\n",
       "      <th>query</th>\n",
       "      <th>doc_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>analysis of mammalian lens proteins by electro...</td>\n",
       "      <td>the crystalline lens in vertebrates, including...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>[analysis, mammalian, lens, protein, electroph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>an autoradiographic study on cell migration in...</td>\n",
       "      <td>the crystalline lens in vertebrates, including...</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>[autoradiographic, study, cell, migration, eye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lens development.. the differentiation of embr...</td>\n",
       "      <td>the crystalline lens in vertebrates, including...</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>[lens, development, differentiation, embryonic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>studies on aging with horse crystalline lens g...</td>\n",
       "      <td>the crystalline lens in vertebrates, including...</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>[study, age, horse, crystalline, lens, gel, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>histological research on the lens in condition...</td>\n",
       "      <td>the crystalline lens in vertebrates, including...</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>[histological, research, lens, condition, hypo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                docs  \\\n",
       "0  analysis of mammalian lens proteins by electro...   \n",
       "1  an autoradiographic study on cell migration in...   \n",
       "2  lens development.. the differentiation of embr...   \n",
       "3  studies on aging with horse crystalline lens g...   \n",
       "4  histological research on the lens in condition...   \n",
       "\n",
       "                                             queries  doc  query  \\\n",
       "0  the crystalline lens in vertebrates, including...   13      1   \n",
       "1  the crystalline lens in vertebrates, including...   14      1   \n",
       "2  the crystalline lens in vertebrates, including...   15      1   \n",
       "3  the crystalline lens in vertebrates, including...   72      1   \n",
       "4  the crystalline lens in vertebrates, including...   79      1   \n",
       "\n",
       "                                       doc_tokenized  \n",
       "0  [analysis, mammalian, lens, protein, electroph...  \n",
       "1  [autoradiographic, study, cell, migration, eye...  \n",
       "2  [lens, development, differentiation, embryonic...  \n",
       "3  [study, age, horse, crystalline, lens, gel, co...  \n",
       "4  [histological, research, lens, condition, hypo...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Cleaning and Tokenizing...')\n",
    "%time final_df['doc_tokenized'] = final_df['docs'].map(lambda x: spacy_tokenizer(x))\n",
    "\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c968b2ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1676118571431,
     "user": {
      "displayName": "Vijjeswarapu Surya Teja",
      "userId": "00235380156444321068"
     },
     "user_tz": -330
    },
    "id": "c968b2ee",
    "outputId": "0fb19434-20f9-4077-aeed-dc4d5c4544e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [analysis, mammalian, lens, protein, electroph...\n",
       "1    [autoradiographic, study, cell, migration, eye...\n",
       "2    [lens, development, differentiation, embryonic...\n",
       "3    [study, age, horse, crystalline, lens, gel, co...\n",
       "4    [histological, research, lens, condition, hypo...\n",
       "Name: doc_tokenized, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_text = final_df['doc_tokenized']\n",
    "doc_text[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wCze78lBa-En",
   "metadata": {
    "id": "wCze78lBa-En"
   },
   "source": [
    "# Building Word Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d50f1c52",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1676118571435,
     "user": {
      "displayName": "Vijjeswarapu Surya Teja",
      "userId": "00235380156444321068"
     },
     "user_tz": -330
    },
    "id": "d50f1c52",
    "outputId": "5a8c85a3-be22-4e80-dfd8-bd54585b675e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 140 ms\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "#creating term dictionary\n",
    "%time dictionary = corpora.Dictionary(doc_text)\n",
    "\n",
    "#filter out terms which occurs in less than 4 documents and more than 20% of the documents.\n",
    "#NOTE: Since we have smaller dataset, we will keep this commented for now.\n",
    "\n",
    "#dictionary.filter_extremes(no_below=4, no_above=0.2)\n",
    "\n",
    "#list of few which which can be further removed\n",
    "stoplist = set('and if this can would should could tell stop come go')\n",
    "stop_ids = [dictionary.token2id[stopword] for stopword in stoplist if stopword in dictionary.token2id]\n",
    "dictionary.filter_tokens(stop_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fd15541",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1676118571437,
     "user": {
      "displayName": "Vijjeswarapu Surya Teja",
      "userId": "00235380156444321068"
     },
     "user_tz": -330
    },
    "id": "0fd15541",
    "outputId": "2cd73465-d830-4fcf-daa5-5381d757b40f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['analysis', 0], ['analyze', 1], ['component', 2], ['crystallin', 3], ['detect', 4], ['difference', 5], ['different', 6], ['dimensional', 7], ['electrophoresis', 8], ['fraction', 9], ['fractionation', 10], ['gel', 11], ['lens', 12], ['mammalian', 13], ['mean', 14], ['method', 15], ['number', 16], ['protein', 17], ['provide', 18], ['resolve', 19], ['sensitive', 20], ['specie', 21], ['starch', 22], ['technique', 23], ['vary', 24], ['age', 25], ['alloxan', 26], ['animal', 27], ['appear', 28], ['appendix', 29], ['arc', 30], ['area', 31], ['autoradiographic', 32], ['autoradiography', 33], ['beginning', 34], ['body', 35], ['cataract', 36], ['cell', 37], ['collaboration', 38], ['control', 39], ['count', 40], ['day', 41], ['diabetic', 42], ['diagram', 43], ['distance', 44], ['effect', 45], ['epithelium', 46], ['equal', 47], ['experimental', 48], ['eye', 49], ['frequency', 50]]]\n"
     ]
    }
   ],
   "source": [
    "#print top 50 items from the dictionary with their unique token-id\n",
    "dict_tokens = [[[dictionary[key], dictionary.token2id[dictionary[key]]] for key, value in dictionary.items() if key <= 50]]\n",
    "print (dict_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qgmHZi27bPXH",
   "metadata": {
    "id": "qgmHZi27bPXH"
   },
   "source": [
    "# Feature Extraction (Bag of Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c063e36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1676118571438,
     "user": {
      "displayName": "Vijjeswarapu Surya Teja",
      "userId": "00235380156444321068"
     },
     "user_tz": -330
    },
    "id": "9c063e36",
    "outputId": "b95174b0-e5ee-4f4b-f34f-e4f4584d7fca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('analysis', 1), ('analyze', 2), ('component', 2), ('crystallin', 3), ('detect', 1), ('difference', 1), ('different', 1), ('dimensional', 1), ('electrophoresis', 2), ('fraction', 1), ('fractionation', 1), ('gel', 1), ('lens', 3), ('mammalian', 2), ('mean', 1), ('method', 1), ('number', 1), ('protein', 3), ('provide', 1), ('resolve', 1), ('sensitive', 1), ('specie', 2), ('starch', 1), ('technique', 1), ('vary', 1)], [('lens', 3), ('number', 1), ('age', 1), ('alloxan', 2), ('animal', 1), ('appear', 1), ('appendix', 1), ('arc', 1), ('area', 1), ('autoradiographic', 1), ('autoradiography', 1), ('beginning', 1), ('body', 1), ('cataract', 1), ('cell', 3), ('collaboration', 1), ('control', 1), ('count', 2), ('day', 3), ('diabetic', 5), ('diagram', 1), ('distance', 1), ('effect', 1), ('epithelium', 2), ('equal', 1), ('experimental', 2), ('eye', 2), ('frequency', 2), ('generation', 1), ('gertraude', 1), ('grain', 2), ('histotechnique', 1), ('hour', 3), ('increase', 1), ('injection', 2), ('interpret', 1), ('intraperitoneal', 1), ('investigate', 1), ('label', 3), ('lense', 1), ('long', 1), ('low', 1), ('migration', 1), ('moewis', 1), ('mrs', 1), ('normal', 2), ('note', 1), ('nuclear', 1), ('nucleus', 3), ('observe', 1), ('peak', 2), ('period', 2), ('position', 1), ('predominant', 1), ('prior', 1), ('rat', 4), ('restricted', 1), ('result', 1), ('shift', 2), ('study', 1), ('successive', 1), ('thymidine', 2), ('time', 1), ('week', 1), ('weight', 1)], [('different', 2), ('lens', 8), ('protein', 2), ('cell', 3), ('day', 1), ('experimental', 1), ('eye', 2), ('interpret', 1), ('result', 1), ('study', 1), ('architecture', 1), ('autonomous', 1), ('behavior', 1), ('capable', 1), ('cavity', 1), ('cellular', 1), ('change', 1), ('chick', 2), ('coelom', 1), ('coelomic', 1), ('complete', 1), ('culture', 2), ('cultured', 1), ('cytodifferentiation', 1), ('determinant', 1), ('determine', 1), ('develop', 1), ('development', 1), ('differentiation', 2), ('embryo', 1), ('embryonic', 5), ('environment', 1), ('epithelial', 4), ('examine', 1), ('explant', 1), ('explantation', 3), ('fail', 1), ('fiber', 2), ('fluid', 1), ('follow', 3), ('form', 1), ('formation', 2), ('growth', 1), ('histologically', 1), ('independent', 1), ('initiation', 1), ('internal', 1), ('lensectomized', 1), ('limited', 1), ('material', 1), ('maturation', 1), ('medium', 2), ('morphogenetic', 1), ('necessary', 1), ('overall', 1), ('planimetry', 1), ('reimplantation', 2), ('respond', 1), ('response', 1), ('resumption', 1), ('return', 1), ('section', 1), ('serial', 1), ('shape', 1), ('situation', 1), ('small', 1), ('speciman', 1), ('specimen', 1), ('sufficient', 1), ('supplement', 2), ('support', 1), ('total', 1), ('undergo', 1), ('vitro', 1), ('vivo', 1), ('volume', 1)]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(desc) for desc in doc_text]\n",
    "\n",
    "word_frequencies = [[(dictionary[id], frequency) for id, frequency in line] for line in corpus[0:3]]\n",
    "\n",
    "print(word_frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NRfoIurgbdMw",
   "metadata": {
    "id": "NRfoIurgbdMw"
   },
   "source": [
    "\n",
    "# Build Tf-Idf and LSI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5811d362",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2089,
     "status": "ok",
     "timestamp": 1676118573481,
     "user": {
      "displayName": "Vijjeswarapu Surya Teja",
      "userId": "00235380156444321068"
     },
     "user_tz": -330
    },
    "id": "5811d362",
    "outputId": "dff40326-dc8f-4545-e754-e346faf20504"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 95.8 ms\n"
     ]
    }
   ],
   "source": [
    "%time doc_tfidf_model = gensim.models.TfidfModel(corpus, id2word=dictionary)\n",
    "%time doc_lsi_model = gensim.models.LsiModel(doc_tfidf_model[corpus], id2word=dictionary, num_topics=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c28e4a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 707,
     "status": "ok",
     "timestamp": 1676118574179,
     "user": {
      "displayName": "Vijjeswarapu Surya Teja",
      "userId": "00235380156444321068"
     },
     "user_tz": -330
    },
    "id": "1c28e4a0",
    "outputId": "524e8585-02a2-4004-9f81-21352150f93e"
   },
   "outputs": [],
   "source": [
    "%time gensim.corpora.MmCorpus.serialize('doc_tfidf_model_mm', doc_tfidf_model[corpus])\n",
    "%time gensim.corpora.MmCorpus.serialize('doc_lsi_model_mm',doc_lsi_model[doc_tfidf_model[corpus]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c2389e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1676118574180,
     "user": {
      "displayName": "Vijjeswarapu Surya Teja",
      "userId": "00235380156444321068"
     },
     "user_tz": -330
    },
    "id": "44c2389e",
    "outputId": "557b67ab-f0b7-450a-ec5d-a92a676ee5cf"
   },
   "outputs": [],
   "source": [
    "#Load the indexed corpus\n",
    "doc_tfidf_corpus = gensim.corpora.MmCorpus('doc_tfidf_model_mm')\n",
    "doc_lsi_corpus = gensim.corpora.MmCorpus('doc_lsi_model_mm')\n",
    "\n",
    "print(doc_tfidf_corpus)\n",
    "print(doc_lsi_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pU_C4X5Vbuhx",
   "metadata": {
    "id": "pU_C4X5Vbuhx"
   },
   "source": [
    "# Doc Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I1_oYENCOTST",
   "metadata": {
    "executionInfo": {
     "elapsed": 625,
     "status": "ok",
     "timestamp": 1676118574801,
     "user": {
      "displayName": "Vijjeswarapu Surya Teja",
      "userId": "00235380156444321068"
     },
     "user_tz": -330
    },
    "id": "I1_oYENCOTST"
   },
   "outputs": [],
   "source": [
    "from gensim.similarities import MatrixSimilarity\n",
    "\n",
    "doc_index = MatrixSimilarity(doc_lsi_corpus, num_features = doc_lsi_corpus.num_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zeIqgp7DOUDm",
   "metadata": {
    "executionInfo": {
     "elapsed": 628,
     "status": "ok",
     "timestamp": 1676118575427,
     "user": {
      "displayName": "Vijjeswarapu Surya Teja",
      "userId": "00235380156444321068"
     },
     "user_tz": -330
    },
    "id": "zeIqgp7DOUDm"
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "only_queries = df_queries['W'].tolist()\n",
    "doc_names = []\n",
    "\n",
    "for query in only_queries:\n",
    "    \n",
    "    query_bow = dictionary.doc2bow(spacy_tokenizer(query))\n",
    "    query_tfidf = doc_tfidf_model[query_bow]\n",
    "    query_lsi = doc_lsi_model[query_tfidf]\n",
    "\n",
    "    doc_index.num_best = 30\n",
    "\n",
    "    doc_list = doc_index[query_lsi]\n",
    "\n",
    "    doc_list.sort(key=itemgetter(1), reverse=True)\n",
    "\n",
    "    for j, doc in enumerate(doc_list):\n",
    "\n",
    "        doc_names.append (\n",
    "            {\n",
    "                'Queries': final_df['queries'][doc[0]],\n",
    "                'Docs': final_df['docs'][doc[0]],\n",
    "                'Query_id': final_df['query'][doc[0]],\n",
    "                'Doc_id': final_df['doc'][doc[0]],\n",
    "                'Relevance_Score': round((doc[1] * 100),2)\n",
    "            }\n",
    "\n",
    "        )\n",
    "        if j == (doc_index.num_best-1):\n",
    "            break\n",
    "\n",
    "doc_names_df = pd.DataFrame(doc_names, columns=['Queries','Docs', 'Query_id', 'Doc_id', 'Relevance_Score'])\n",
    "\n",
    "ranking_df = doc_names_df.sort_values(by=['Query_id', 'Relevance_Score'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ewOq02z2OXc5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1676118575430,
     "user": {
      "displayName": "Vijjeswarapu Surya Teja",
      "userId": "00235380156444321068"
     },
     "user_tz": -330
    },
    "id": "ewOq02z2OXc5",
    "outputId": "f43da5c9-b8c4-491c-b0c3-b31f73b96564"
   },
   "outputs": [],
   "source": [
    "ranking_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KlGzUjikOZ9v",
   "metadata": {
    "executionInfo": {
     "elapsed": 780,
     "status": "ok",
     "timestamp": 1676118595095,
     "user": {
      "displayName": "Vijjeswarapu Surya Teja",
      "userId": "00235380156444321068"
     },
     "user_tz": -330
    },
    "id": "KlGzUjikOZ9v"
   },
   "outputs": [],
   "source": [
    "#ranking_df.to_csv('query_doc_ranking.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
